{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dd055a02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd055a02",
        "outputId": "838aa59a-6610-41d5-914f-9230f14dda64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dspy in /usr/local/lib/python3.10/dist-packages (2.5.41)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from dspy) (2.2.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from dspy) (3.1.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from dspy) (5.6.3)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from dspy) (0.27.2)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.10/dist-packages (from dspy) (1.4.2)\n",
            "Requirement already satisfied: json-repair in /usr/local/lib/python3.10/dist-packages (from dspy) (0.30.2)\n",
            "Requirement already satisfied: litellm==1.51.0 in /usr/local/lib/python3.10/dist-packages (from dspy) (1.51.0)\n",
            "Requirement already satisfied: magicattr~=0.1.6 in /usr/local/lib/python3.10/dist-packages (from dspy) (0.1.6)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from dspy) (1.54.4)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from dspy) (4.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dspy) (2.2.2)\n",
            "Requirement already satisfied: pydantic~=2.0 in /usr/local/lib/python3.10/dist-packages (from dspy) (2.9.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from dspy) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dspy) (2.32.3)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from dspy) (9.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dspy) (4.66.6)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from dspy) (5.10.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from dspy) (3.7.1)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from dspy) (0.0.8)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (3.11.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (4.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (1.0.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm==1.51.0->dspy) (0.20.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio->dspy) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->dspy) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->dspy) (1.2.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai->dspy) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai->dspy) (0.7.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai->dspy) (4.12.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->dspy) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->dspy) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->dspy) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.0->dspy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.0->dspy) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dspy) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dspy) (2.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->dspy) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy) (6.0.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->dspy) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->dspy) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna->dspy) (2.0.36)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy) (2024.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->dspy) (1.3.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm==1.51.0->dspy) (4.0.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm==1.51.0->dspy) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.51.0->dspy) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy) (0.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dspy) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna->dspy) (3.1.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.21)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U dspy\n",
        "!pip install langchain\n",
        "!pip install -qU langchain-community faiss-cpu\n",
        "!pip install --upgrade --quiet  llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHkOxQeF6LbR",
        "outputId": "175720df-8f2c-4cac-bfae-81511640fc5a"
      },
      "id": "sHkOxQeF6LbR",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/Colab\\ Notebooks/GST-QA/* .\n",
        "mkdir llama-model/"
      ],
      "metadata": {
        "id": "t5c3_eVZ6o54"
      },
      "id": "t5c3_eVZ6o54",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bC7GZee09oDl"
      },
      "id": "bC7GZee09oDl",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')"
      ],
      "metadata": {
        "id": "FVCZxRRq8e2f"
      },
      "id": "FVCZxRRq8e2f",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "hf_hub_download(repo_id=\"bartowski/Llama-3.2-1B-Instruct-GGUF\", filename=\"Llama-3.2-1B-Instruct-Q6_K.gguf\", local_dir='llama-model/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "q38owZ7I7IcO",
        "outputId": "b532db48-6a7e-4239-d2c5-aae09a2af8db"
      },
      "id": "q38owZ7I7IcO",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'llama-model/Llama-3.2-1B-Instruct-Q6_K.gguf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1a6acb0d",
      "metadata": {
        "id": "1a6acb0d"
      },
      "outputs": [],
      "source": [
        "from settings import *\n",
        "import dspy\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6b52a8e7",
      "metadata": {
        "id": "6b52a8e7"
      },
      "outputs": [],
      "source": [
        "# Local Anthropic\n",
        "import dspy\n",
        "lm = dspy.LM('anthropic/claude-3-opus-20240229')\n",
        "dspy.configure(lm=lm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfc9235b",
      "metadata": {
        "id": "dfc9235b"
      },
      "outputs": [],
      "source": [
        "# Local Ollama\n",
        "# from litellm import completion\n",
        "\n",
        "# llama = dspy.LM(\n",
        "#     \"ollama_chat/localllama\",\n",
        "#     model_type=\"chat\",\n",
        "#     temperature=TEMPRATURE,\n",
        "#     api_base=\"http://localhost:11434\",\n",
        "# )\n",
        "# dspy.configure(lm=llama)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d08690",
      "metadata": {
        "id": "09d08690"
      },
      "outputs": [],
      "source": [
        "# Local LLAMA CPP (DEPRECATED: Has issues)\n",
        "\n",
        "# REF-1: LLAMA CPP: https://dspy.ai/deep-dive/language_model_clients/lm_local_models/LlamaCpp/?h=l\n",
        "# REF-2: GENERAL RAG:  https://dspy.ai/tutorials/rag/#configuring-the-dspy-environment\n",
        "# REF-3: https://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
        "\n",
        "# from llama_cpp import Llama\n",
        "\n",
        "\n",
        "# llm = Llama(\n",
        "#     temperature=0.2,\n",
        "#     model_path=MODEL_PATH,\n",
        "#     n_ctx=(N_DOCS_RETREIVE+2)*CHUNK_SIZE,\n",
        "#     n_gpu_layers=-1,\n",
        "#     n_batch=32,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "#     max_tokens=4098,\n",
        "#     top_p=1,\n",
        "#     verbose=False\n",
        "# )\n",
        "\n",
        "# llamalm = dspy.LlamaCpp(model=\"llama\", llama_model=llm,  model_type=\"chat\", temperature=TEMPRATURE)\n",
        "# dspy.configure(lm=llamalm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "76669ef1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76669ef1",
        "outputId": "2673c9af-0eb9-4e17-df44-5c0c12fcab10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data 48 is loaded.\n"
          ]
        }
      ],
      "source": [
        "# Loading Data\n",
        "with open(QUESTION_FILE) as q_f:\n",
        "    questions = json.load(q_f)\n",
        "\n",
        "# Mapping To DSPy Mapping\n",
        "questions = [{'question': q['question'], 'response': q['answer']} for q in questions]\n",
        "print(f\"Data {len(questions)} is loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "38445df3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38445df3",
        "outputId": "0038149b-6cd9-4a82-d23b-af021cd2a7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Divided 48 to \n",
            " Train:9 Test: 21 Dev:18\n"
          ]
        }
      ],
      "source": [
        "# Preparing Data\n",
        "import random\n",
        "\n",
        "data = [dspy.Example(**q).with_inputs('question') for q in questions]\n",
        "# Splitting Data Train, Dev=2*Train, Test=2*Train\n",
        "n_data = len(data)\n",
        "n_train, n_test = int(n_data/5), 2*int(n_data/5)\n",
        "n_dev = n_data - n_train - n_test\n",
        "\n",
        "random.Random(0).shuffle(data)\n",
        "trainset, devset, testset = data[:n_train], data[n_train:n_train+n_test], data[n_train+n_test:n_data]\n",
        "print(f\"Divided {n_data} to \\n Train:{len(trainset)} Test: {len(testset)} Dev:{len(devset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "75fafb13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75fafb13",
        "outputId": "0bd19cca-b277-4ebd-c13d-22fb7a6b6e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_new_context_with_model: n_ctx_per_seq (12000) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 17 Documents\n"
          ]
        }
      ],
      "source": [
        "# Loading the vector_store of Langchain\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from utils import LlamaCppEmbeddingsFix\n",
        "\n",
        "embeding = LlamaCppEmbeddingsFix(\n",
        "    model_path=MODEL_PATH, verbose=False,\n",
        "    n_ctx=(N_DOCS_RETREIVE+2)*CHUNK_SIZE,\n",
        ")\n",
        "\n",
        "vector_store = FAISS.load_local(\n",
        "    VECTOR_STORE,\n",
        "    embeddings=embeding,\n",
        "    allow_dangerous_deserialization=True\n",
        ")\n",
        "vector_store.load_local(VECTOR_STORE, embeddings=embeding, allow_dangerous_deserialization=True)\n",
        "print(f\"Loaded {vector_store.index.ntotal} Documents\")\n",
        "\n",
        "retriever = vector_store.as_retriever(\n",
        "    search_type=SEARCH_METHOD,\n",
        "    search_kwargs={\n",
        "    'k': N_DOCS_RETREIVE,\n",
        "    'score_threshold': SCORE_THRESH\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "622fd65e",
      "metadata": {
        "id": "622fd65e"
      },
      "outputs": [],
      "source": [
        "from dspy.evaluate import SemanticF1\n",
        "\n",
        "# RAG Based\n",
        "def search(question):\n",
        "    docs = retriever.invoke(question)\n",
        "    return \"\".join(f\"Page {d.metadata['page']}\\n\"+d.page_content for d in docs)\n",
        "\n",
        "class RAG(dspy.Module):\n",
        "    def __init__(self):\n",
        "        self.respond = dspy.ChainOfThought('context, question -> response')\n",
        "\n",
        "    def forward(self, question):\n",
        "        context = search(question)\n",
        "        #print(\"Context Created\", context)\n",
        "        return self.respond(context=context, question=question)\n",
        "\n",
        "metric = SemanticF1(decompositional=True)\n",
        "rag = RAG()\n",
        "evaluate = dspy.Evaluate(devset=devset, metric=metric, num_threads=1, display_progress=True, display_table=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "92a5bece",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92a5bece",
        "outputId": "a9f60f7c-0fdc-40b6-ee52-f96f669e6a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####### Example ######### \n",
            " Example({'question': 'How can you filter the admission inquiry list?', 'response': 'By date, standard, enquiry number, name, or contact number'}) (input_keys={'question'})\n",
            "############ Pred ############## \n",
            " Prediction(\n",
            "    reasoning='Based on the information provided in the operational manual, there are two ways to filter the admission inquiry list:\\n\\n1. Activity Date Wise Report - This allows you to check date wise admission enquiry details by selecting specific dates and clicking the search icon.\\n\\n2. Follow Up Date Wise Report - This also allows filtering the admission enquiry list by selecting specific follow up dates and clicking the search icon to see the date wise follow up report.\\n\\nSo in summary, the admission inquiry list can be filtered either by activity date or by follow up date to narrow down the results.',\n",
            "    response='According to the operational manual, there are two ways to filter the admission inquiry list:\\n\\n1. Using the Activity Date Wise Report - Select specific dates and click the search icon to view the admission enquiries for those dates.\\n\\n2. Using the Follow Up Date Wise Report - Select specific follow up dates and click the search icon to view the follow ups scheduled for those dates.'\n",
            ")\n",
            "############ Score ############## \n",
            " 0.33333333333333337\n"
          ]
        }
      ],
      "source": [
        "# Single Test Run\n",
        "example = trainset[0]\n",
        "pred = rag(question=example.question)\n",
        "score = metric(example, pred)\n",
        "\n",
        "print(\"####### Example ######### \\n\", example)\n",
        "print(\"############ Pred ############## \\n\", pred)\n",
        "print(\"############ Score ############## \\n\", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adaa1703",
      "metadata": {
        "id": "adaa1703"
      },
      "outputs": [],
      "source": [
        "dspy.inspect_history()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c3806914",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "c3806914",
        "outputId": "51992828-c798-4209-c2b6-1d3ab0afd419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 13.81 / 18 (76.7%): 100%|██████████| 18/18 [06:49<00:00, 22.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:03:22 INFO dspy.evaluate.evaluate: Average Metric: 13.809770638718009 / 18 (76.7%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                        question  \\\n",
              "0  What is required to save a registration form?   \n",
              "1             How do you generate an MIS report?   \n",
              "\n",
              "                                      example_response  \\\n",
              "0             Fill all required details and click Save   \n",
              "1  Select the required report level and click Generate   \n",
              "\n",
              "                                                               reasoning  \\\n",
              "0  According to the information provided on page 8, to save a registr...   \n",
              "1  The given context does not provide information on how to generate ...   \n",
              "\n",
              "                                                           pred_response  \\\n",
              "0  To save a registration form, you need to fill in the registration ...   \n",
              "1  I apologize, the information provided in the given context does no...   \n",
              "\n",
              "   SemanticF1  \n",
              "0  ✔️ [1.000]  \n",
              "1              "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbb3375e-fd7f-4f3f-aae2-0527e1ff3d95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>example_response</th>\n",
              "      <th>reasoning</th>\n",
              "      <th>pred_response</th>\n",
              "      <th>SemanticF1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is required to save a registration form?</td>\n",
              "      <td>Fill all required details and click Save</td>\n",
              "      <td>According to the information provided on page 8, to save a registr...</td>\n",
              "      <td>To save a registration form, you need to fill in the registration ...</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How do you generate an MIS report?</td>\n",
              "      <td>Select the required report level and click Generate</td>\n",
              "      <td>The given context does not provide information on how to generate ...</td>\n",
              "      <td>I apologize, the information provided in the given context does no...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbb3375e-fd7f-4f3f-aae2-0527e1ff3d95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbb3375e-fd7f-4f3f-aae2-0527e1ff3d95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbb3375e-fd7f-4f3f-aae2-0527e1ff3d95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-920a2aaa-4334-4d0f-a45f-d80015fe4817\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-920a2aaa-4334-4d0f-a45f-d80015fe4817')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-920a2aaa-4334-4d0f-a45f-d80015fe4817 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"evaluate(rag)\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"How do you generate an MIS report?\",\n          \"What is required to save a registration form?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"example_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Select the required report level and click Generate\",\n          \"Fill all required details and click Save\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reasoning\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"The given context does not provide information on how to generate an MIS report specifically. It mentions that MIS reports are part of the Fees...\",\n          \"According to the information provided on page 8, to save a registration form you need to: 1. Click on \\\"Push to Registration\\\" from the three...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"I apologize, the information provided in the given context does not include specific steps on how to generate an MIS report in the QLS Platform....\",\n          \"To save a registration form, you need to fill in the registration form with the required details and click on the \\\"Save\\\" button.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SemanticF1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\",\n          \"\\u2714\\ufe0f [1.000]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "                <div style='\n",
              "                    text-align: center;\n",
              "                    font-size: 16px;\n",
              "                    font-weight: bold;\n",
              "                    color: #555;\n",
              "                    margin: 10px 0;'>\n",
              "                    ... 16 more rows not displayed ...\n",
              "                </div>\n",
              "                "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76.72"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Raw Performance\n",
        "evaluate(rag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8d4426c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d4426c9",
        "outputId": "0860d0a6-df30-4bcc-e03b-f171e6c311f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:06:39 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
            "num_trials: 25\n",
            "minibatch: False\n",
            "num_candidates: 19\n",
            "valset size: 7\n",
            "\n",
            "2024/12/03 15:06:39 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
            "2024/12/03 15:06:39 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
            "\n",
            "2024/12/03 15:06:39 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=19 sets of demonstrations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapping set 1/19\n",
            "Bootstrapping set 2/19\n",
            "Bootstrapping set 3/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:40<00:00, 20.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 4/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:02<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 5/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:04<00:00,  2.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 6/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:06<00:00,  3.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 7/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:02<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 8/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:02<00:00,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 9/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 1/2 [00:01<00:01,  1.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 10/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 1/2 [00:01<00:01,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 11/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 1/2 [00:02<00:02,  2.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 12/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:05<00:00,  2.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 13/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:03<00:00,  1.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 14/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:03<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 15/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:05<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 16/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:06<00:00,  3.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 17/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:03<00:00,  1.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 18/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 1/2 [00:01<00:01,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 19/19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:02<00:00,  1.37s/it]\n",
            "2024/12/03 15:08:14 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
            "2024/12/03 15:08:14 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:08:32 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "Proposing instructions...\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Given the fields `context`, `question`, produce the fields `response`.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 1: You are an AI assistant that answers questions by reasoning step-by-step. You will be given a context containing relevant information and a question. Your task is to:\n",
            "\n",
            "1. Carefully read the provided context to understand the key facts and details.\n",
            "2. Analyze the question to determine what information is being asked for. \n",
            "3. Reason through the question step-by-step, combining relevant parts of the context in a logical way to arrive at an answer. Explain your reasoning process.\n",
            "4. Provide a clear, concise response that directly answers the question based on your reasoning and the given context.\n",
            "\n",
            "Remember to stick to only the information provided in the context when generating your response. If the context does not contain sufficient information to answer the question, indicate that in your response rather than making assumptions or guesses.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Given the provided `context` which contains relevant information from an operational manual, carefully analyze the `question` to determine what key details are needed to answer it. Formulate a step-by-step `reasoning` process that logically breaks down the question and uses evidence from the context to arrive at a conclusion. The reasoning should cite specific details from the context that support the final `response`. Ensure the response directly addresses the question asked, is factual and concise, and fully captures the relevant information from the context without including any unnecessary or speculative details not supported by the provided context.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Imagine you are an AI assistant embedded in the administrative software system for an educational institution. Your role is to help staff, students and parents quickly find information and answers related to admissions, fees, logistics and general policies. \n",
            "\n",
            "Given the provided `context` from the institution's operational manual, and a `question` from a user, your task is to:\n",
            "\n",
            "1. Analyze the question to determine what information is being requested\n",
            "2. Search through the provided context to find the relevant details needed to answer the question\n",
            "3. Reason step-by-step, explaining your thought process, to derive the final answer based on the contextual information\n",
            "4. Provide a concise `response` that directly answers the original question\n",
            "\n",
            "The `reasoning` and `response` you generate should be factual, practical and to-the-point. Refrain from speculation or opinions, and instead focus on surfacing the key details from the manual that address the question. If the question cannot be satisfactorily answered by the given context, simply state that the information to answer the question is not available.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 4: You will be provided with two input fields:\n",
            "- `context`: This will contain relevant information from an institution's operational manual that may help answer the question. Review the context carefully to find details related to the question.\n",
            "- `question`: This is the question that needs to be answered based on the given context.\n",
            "\n",
            "Using the provided context, generate a step-by-step reasoning process to derive the answer to the question, outputting it in the `reasoning` field. Avoid making claims that are not directly supported by the context.\n",
            "\n",
            "After the reasoning, provide a concise `response` that directly answers the question asked. The response should be factual and aligned with the preceding reasoning.\n",
            "\n",
            "If the question cannot be satisfactorily answered based on the given context, indicate that in the response.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 5: Imagine you are an AI assistant embedded in the administrative software system for an educational institution. Your role is to help staff, students and parents quickly find information and answers related to admissions, fees, logistics and general policies. \n",
            "\n",
            "Given the provided `context` from the institution's operational manual, and a `question` from a user, your task is to:\n",
            "\n",
            "1. Analyze the question to determine what information is being requested\n",
            "2. Search through the provided context to find the relevant details needed to answer the question\n",
            "3. Reason step-by-step, explaining your thought process, to derive the final answer based on the contextual information\n",
            "4. Provide a concise `response` that directly answers the original question\n",
            "\n",
            "The `reasoning` and `response` you generate should be factual, practical and to-the-point. Refrain from speculation or opinions, and instead focus on surfacing the key details from the manual that address the question. If the question cannot be satisfactorily answered by the given context, simply state that the information to answer the question is not available.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 6: Given the provided `context` which contains relevant information from an operational manual, carefully analyze the `question` to determine what key details are needed to answer it. Formulate a step-by-step `reasoning` process that logically breaks down the question and uses evidence from the context to arrive at a conclusion. The reasoning should cite specific details from the context that support the final `response`. Ensure the response directly addresses the question asked, is factual and concise, and fully captures the relevant information from the context without including any unnecessary or speculative details not supported by the provided context.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 7: You are an AI assistant that helps answer questions about an educational institution's policies and procedures. Given the context from the institution's operational manual and a question, provide a thoughtful, step-by-step reasoning process to derive the answer from the relevant details in the manual. Clearly state the final answer in the response.\n",
            "\n",
            "Context: ${context}\n",
            "\n",
            "Question: ${question}\n",
            "\n",
            "Reasoning: Let's think step by step in order to ${reasoning}\n",
            "\n",
            "Response: ${response}\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 8: You will be provided with two input fields:\n",
            "- `context`: This will contain relevant information from an institution's operational manual that may help answer the question. Review the context carefully to find details related to the question.\n",
            "- `question`: This is the question that needs to be answered based on the given context.\n",
            "\n",
            "Using the provided context, generate a step-by-step reasoning process to derive the answer to the question, outputting it in the `reasoning` field. Avoid making claims that are not directly supported by the context.\n",
            "\n",
            "After the reasoning, provide a concise `response` that directly answers the question asked. The response should be factual and aligned with the preceding reasoning.\n",
            "\n",
            "If the question cannot be satisfactorily answered based on the given context, indicate that in the response.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 9: You are an AI assistant deployed at an educational institution to help answer questions from staff, students and parents. You have access to the institution's operational manual, which has been provided as context. Given this context and an input question, your task is to:\n",
            "\n",
            "1. Carefully analyze the question to determine what information is being requested\n",
            "2. Search through the provided context to find the relevant details needed to answer the question \n",
            "3. Reason step-by-step, combining information from the context as needed, to derive the answer\n",
            "4. Provide a clear, concise response that fully addresses the question asked\n",
            "\n",
            "The accuracy and helpfulness of your responses is critical, as people will be relying on you for important information regarding admissions, fee payments, policies and procedures. If the answer cannot be found in the given context, simply say \"I do not have enough information to answer this question.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 10: You will be provided with two input fields:\n",
            "- `context`: This will contain relevant information from an institution's operational manual that may help answer the question. Review the context carefully to find details related to the question.\n",
            "- `question`: This is the question that needs to be answered based on the given context.\n",
            "\n",
            "Using the provided context, generate a step-by-step reasoning process to derive the answer to the question, outputting it in the `reasoning` field. Avoid making claims that are not directly supported by the context.\n",
            "\n",
            "After the reasoning, provide a concise `response` that directly answers the question asked. The response should be factual and aligned with the preceding reasoning.\n",
            "\n",
            "If the question cannot be satisfactorily answered based on the given context, indicate that in the response.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 11: You will be provided with two input fields:\n",
            "- `context`: This will contain relevant information from an institution's operational manual that may help answer the question. Review the context carefully to find details related to the question.\n",
            "- `question`: This is the question that needs to be answered based on the given context.\n",
            "\n",
            "Using the provided context, generate a step-by-step reasoning process to derive the answer to the question, outputting it in the `reasoning` field. Avoid making claims that are not directly supported by the context.\n",
            "\n",
            "After the reasoning, provide a concise `response` that directly answers the question asked. The response should be factual and aligned with the preceding reasoning.\n",
            "\n",
            "If the question cannot be satisfactorily answered based on the given context, indicate that in the response.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 12: You are an AI assistant deployed at an educational institution to help answer questions from staff, students and parents. You have access to the institution's operational manual, which has been provided as context. Given this context and an input question, your task is to:\n",
            "\n",
            "1. Carefully analyze the question to determine what information is being requested\n",
            "2. Search through the provided context to find the relevant details needed to answer the question \n",
            "3. Reason step-by-step, combining information from the context as needed, to derive the answer\n",
            "4. Provide a clear, concise response that fully addresses the question asked\n",
            "\n",
            "The accuracy and helpfulness of your responses is critical, as people will be relying on you for important information regarding admissions, fee payments, policies and procedures. If the answer cannot be found in the given context, simply say \"I do not have enough information to answer this question.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 13: Imagine you are an AI assistant embedded in the administrative software system for an educational institution. Your role is to help staff, students and parents quickly find information and answers related to admissions, fees, logistics and general policies. \n",
            "\n",
            "Given the provided `context` from the institution's operational manual, and a `question` from a user, your task is to:\n",
            "\n",
            "1. Analyze the question to determine what information is being requested\n",
            "2. Search through the provided context to find the relevant details needed to answer the question\n",
            "3. Reason step-by-step, explaining your thought process, to derive the final answer based on the contextual information\n",
            "4. Provide a concise `response` that directly answers the original question\n",
            "\n",
            "The `reasoning` and `response` you generate should be factual, practical and to-the-point. Refrain from speculation or opinions, and instead focus on surfacing the key details from the manual that address the question. If the question cannot be satisfactorily answered by the given context, simply state that the information to answer the question is not available.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 14: Imagine you are an AI assistant embedded in the administrative software system for an educational institution. Your role is to help staff, students and parents quickly find information and answers related to admissions, fees, logistics and general policies. \n",
            "\n",
            "Given the provided `context` from the institution's operational manual, and a `question` from a user, your task is to:\n",
            "\n",
            "1. Analyze the question to determine what information is being requested\n",
            "2. Search through the provided context to find the relevant details needed to answer the question\n",
            "3. Reason step-by-step, explaining your thought process, to derive the final answer based on the contextual information\n",
            "4. Provide a concise `response` that directly answers the original question\n",
            "\n",
            "The `reasoning` and `response` you generate should be factual, practical and to-the-point. Refrain from speculation or opinions, and instead focus on surfacing the key details from the manual that address the question. If the question cannot be satisfactorily answered by the given context, simply state that the information to answer the question is not available.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 15: Given the provided context, answer the question by first providing step-by-step reasoning to arrive at the answer, and then provide the final response.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 16: You will be provided with two input fields:\n",
            "- `context`: This will contain relevant information from an institution's operational manual that may help answer the question. Review the context carefully to find details related to the question.\n",
            "- `question`: This is the question that needs to be answered based on the given context.\n",
            "\n",
            "Using the provided context, generate a step-by-step reasoning process to derive the answer to the question, outputting it in the `reasoning` field. Avoid making claims that are not directly supported by the context.\n",
            "\n",
            "After the reasoning, provide a concise `response` that directly answers the question asked. The response should be factual and aligned with the preceding reasoning.\n",
            "\n",
            "If the question cannot be satisfactorily answered based on the given context, indicate that in the response.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 17: You will be provided with two input fields:\n",
            "- `context`: This will contain relevant information from an institution's operational manual that may help answer the question. Review the context carefully to find details related to the question.\n",
            "- `question`: This is the question that needs to be answered based on the given context.\n",
            "\n",
            "Using the provided context, generate a step-by-step reasoning process to derive the answer to the question, outputting it in the `reasoning` field. Avoid making claims that are not directly supported by the context.\n",
            "\n",
            "After the reasoning, provide a concise `response` that directly answers the question asked. The response should be factual and aligned with the preceding reasoning.\n",
            "\n",
            "If the question cannot be satisfactorily answered based on the given context, indicate that in the response.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: 18: Imagine you are an AI assistant embedded in the administrative software system for an educational institution. Your role is to help staff, students and parents quickly find information and answers related to admissions, fees, logistics and general policies. \n",
            "\n",
            "Given the provided `context` from the institution's operational manual, and a `question` from a user, your task is to:\n",
            "\n",
            "1. Analyze the question to determine what information is being requested\n",
            "2. Search through the provided context to find the relevant details needed to answer the question\n",
            "3. Reason step-by-step, explaining your thought process, to derive the final answer based on the contextual information\n",
            "4. Provide a concise `response` that directly answers the original question\n",
            "\n",
            "The `reasoning` and `response` you generate should be factual, practical and to-the-point. Refrain from speculation or opinions, and instead focus on surfacing the key details from the manual that address the question. If the question cannot be satisfactorily answered by the given context, simply state that the information to answer the question is not available.\n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2024/12/03 15:10:25 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the default program...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 4.13 / 7 (59.0%): 100%|██████████| 7/7 [02:41<00:00, 23.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:13:07 INFO dspy.evaluate.evaluate: Average Metric: 4.1269841269841265 / 7 (59.0%)\n",
            "2024/12/03 15:13:07 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 58.96\n",
            "\n",
            "2024/12/03 15:13:07 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
            "2024/12/03 15:13:07 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "2024/12/03 15:13:07 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 1 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 4.71 / 7 (67.2%): 100%|██████████| 7/7 [03:01<00:00, 25.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:16:08 INFO dspy.evaluate.evaluate: Average Metric: 4.707157114342743 / 7 (67.2%)\n",
            "2024/12/03 15:16:08 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 67.25\n",
            "2024/12/03 15:16:08 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 67.25 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 7'].\n",
            "2024/12/03 15:16:08 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25]\n",
            "2024/12/03 15:16:08 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:16:08 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2024/12/03 15:16:08 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 2.95 / 7 (42.1%): 100%|██████████| 7/7 [02:50<00:00, 24.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:18:59 INFO dspy.evaluate.evaluate: Average Metric: 2.9464733536589827 / 7 (42.1%)\n",
            "2024/12/03 15:18:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.09 with parameters ['Predictor 0: Instruction 10', 'Predictor 0: Few-Shot Set 7'].\n",
            "2024/12/03 15:18:59 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09]\n",
            "2024/12/03 15:18:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:18:59 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2024/12/03 15:18:59 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 3.51 / 7 (50.2%): 100%|██████████| 7/7 [02:54<00:00, 24.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:21:53 INFO dspy.evaluate.evaluate: Average Metric: 3.5114929539417408 / 7 (50.2%)\n",
            "2024/12/03 15:21:53 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.16 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 18'].\n",
            "2024/12/03 15:21:53 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16]\n",
            "2024/12/03 15:21:53 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:21:53 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2024/12/03 15:21:53 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 3.97 / 7 (56.8%): 100%|██████████| 7/7 [02:50<00:00, 24.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:24:44 INFO dspy.evaluate.evaluate: Average Metric: 3.9731960423146213 / 7 (56.8%)\n",
            "2024/12/03 15:24:44 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 56.76 with parameters ['Predictor 0: Instruction 15', 'Predictor 0: Few-Shot Set 2'].\n",
            "2024/12/03 15:24:44 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76]\n",
            "2024/12/03 15:24:44 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:24:44 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2024/12/03 15:24:44 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 2.95 / 7 (42.1%): 100%|██████████| 7/7 [00:11<00:00,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:24:55 INFO dspy.evaluate.evaluate: Average Metric: 2.9464733536589827 / 7 (42.1%)\n",
            "2024/12/03 15:24:55 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.09 with parameters ['Predictor 0: Instruction 8', 'Predictor 0: Few-Shot Set 18'].\n",
            "2024/12/03 15:24:55 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09]\n",
            "2024/12/03 15:24:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:24:55 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2024/12/03 15:24:55 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 1.00 / 7 (14.3%):  29%|██▊       | 2/7 [00:46<01:52, 22.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:25:44 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where do you enter installment details?', 'response': 'In the Fees Master under Fees Installment'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 1.00 / 7 (14.3%):  43%|████▎     | 3/7 [00:48<00:52, 13.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:25:46 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where can you find MIS reports in the fees management module?', 'response': 'At multiple levels, from individual students to top management'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 1.00 / 7 (14.3%):  57%|█████▋    | 4/7 [00:50<00:26,  8.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:25:48 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of fee category titles?', 'response': 'To classify different types of fees'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 1.00 / 7 (14.3%):  71%|███████▏  | 5/7 [00:52<00:12,  6.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:25:50 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'How do you open a new registration form?', 'response': 'Click Registration > New Registration'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 1.00 / 7 (14.3%):  86%|████████▌ | 6/7 [00:55<00:05,  5.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:25:54 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What are the three steps in the admission process?', 'response': 'Inquiry, Registration, Admission'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 1.00 / 7 (14.3%): 100%|██████████| 7/7 [00:58<00:00,  8.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:25:54 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 7 (14.3%)\n",
            "2024/12/03 15:25:54 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 14.29 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 1'].\n",
            "2024/12/03 15:25:54 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29]\n",
            "2024/12/03 15:25:54 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:25:54 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2024/12/03 15:25:54 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 3.51 / 7 (50.2%): 100%|██████████| 7/7 [00:08<00:00,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:03 INFO dspy.evaluate.evaluate: Average Metric: 3.5114929539417408 / 7 (50.2%)\n",
            "2024/12/03 15:26:03 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.16 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 12'].\n",
            "2024/12/03 15:26:03 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16]\n",
            "2024/12/03 15:26:03 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:26:03 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2024/12/03 15:26:03 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 2.95 / 7 (42.1%): 100%|██████████| 7/7 [00:11<00:00,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:14 INFO dspy.evaluate.evaluate: Average Metric: 2.9464733536589827 / 7 (42.1%)\n",
            "2024/12/03 15:26:14 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.09 with parameters ['Predictor 0: Instruction 11', 'Predictor 0: Few-Shot Set 13'].\n",
            "2024/12/03 15:26:14 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09]\n",
            "2024/12/03 15:26:14 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:26:14 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2024/12/03 15:26:14 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:17 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of the QLS platform?', 'response': 'To provide a well-integrated ERP solution for schools'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  14%|█▍        | 1/7 [00:02<00:12,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:19 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What do badges in the admission inquiry list indicate?', 'response': 'The current status of the student'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  29%|██▊       | 2/7 [00:04<00:10,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:22 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where do you enter installment details?', 'response': 'In the Fees Master under Fees Installment'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  43%|████▎     | 3/7 [00:07<00:09,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:25 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where can you find MIS reports in the fees management module?', 'response': 'At multiple levels, from individual students to top management'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  57%|█████▋    | 4/7 [00:10<00:08,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:27 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of fee category titles?', 'response': 'To classify different types of fees'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  71%|███████▏  | 5/7 [00:12<00:05,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:29 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'How do you open a new registration form?', 'response': 'Click Registration > New Registration'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  86%|████████▌ | 6/7 [00:14<00:02,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:31 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What are the three steps in the admission process?', 'response': 'Inquiry, Registration, Admission'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%): 100%|██████████| 7/7 [00:16<00:00,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:31 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 7 (0.0%)\n",
            "2024/12/03 15:26:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 4'].\n",
            "2024/12/03 15:26:31 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0]\n",
            "2024/12/03 15:26:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:26:31 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2024/12/03 15:26:31 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:33 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of the QLS platform?', 'response': 'To provide a well-integrated ERP solution for schools'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  14%|█▍        | 1/7 [00:02<00:13,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:37 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What do badges in the admission inquiry list indicate?', 'response': 'The current status of the student'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  29%|██▊       | 2/7 [00:05<00:14,  2.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:39 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where do you enter installment details?', 'response': 'In the Fees Master under Fees Installment'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  43%|████▎     | 3/7 [00:08<00:11,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:42 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where can you find MIS reports in the fees management module?', 'response': 'At multiple levels, from individual students to top management'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  57%|█████▋    | 4/7 [00:10<00:07,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:44 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of fee category titles?', 'response': 'To classify different types of fees'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  71%|███████▏  | 5/7 [00:12<00:04,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:46 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'How do you open a new registration form?', 'response': 'Click Registration > New Registration'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  86%|████████▌ | 6/7 [00:14<00:02,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:48 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What are the three steps in the admission process?', 'response': 'Inquiry, Registration, Admission'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%): 100%|██████████| 7/7 [00:16<00:00,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:26:48 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 7 (0.0%)\n",
            "2024/12/03 15:26:48 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 14', 'Predictor 0: Few-Shot Set 1'].\n",
            "2024/12/03 15:26:48 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0]\n",
            "2024/12/03 15:26:48 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:26:48 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:26:48 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 4.71 / 7 (67.2%): 100%|██████████| 7/7 [00:12<00:00,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:27:00 INFO dspy.evaluate.evaluate: Average Metric: 4.707157114342743 / 7 (67.2%)\n",
            "2024/12/03 15:27:00 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 67.25 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 3'].\n",
            "2024/12/03 15:27:00 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25]\n",
            "2024/12/03 15:27:00 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:27:00 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:27:00 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 4.71 / 7 (67.2%): 100%|██████████| 7/7 [00:12<00:00,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:27:12 INFO dspy.evaluate.evaluate: Average Metric: 4.707157114342743 / 7 (67.2%)\n",
            "2024/12/03 15:27:12 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 67.25 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 3'].\n",
            "2024/12/03 15:27:12 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25]\n",
            "2024/12/03 15:27:12 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:27:12 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:27:12 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 4.71 / 7 (67.2%): 100%|██████████| 7/7 [00:10<00:00,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:27:23 INFO dspy.evaluate.evaluate: Average Metric: 4.707157114342743 / 7 (67.2%)\n",
            "2024/12/03 15:27:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 67.25 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 7'].\n",
            "2024/12/03 15:27:23 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25]\n",
            "2024/12/03 15:27:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:27:23 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:27:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 4.71 / 7 (67.2%): 100%|██████████| 7/7 [00:10<00:00,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:27:33 INFO dspy.evaluate.evaluate: Average Metric: 4.707157114342743 / 7 (67.2%)\n",
            "2024/12/03 15:27:33 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 67.25 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 11'].\n",
            "2024/12/03 15:27:33 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25]\n",
            "2024/12/03 15:27:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:27:33 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:27:33 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 2.95 / 7 (42.1%): 100%|██████████| 7/7 [00:11<00:00,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:27:45 INFO dspy.evaluate.evaluate: Average Metric: 2.9464733536589827 / 7 (42.1%)\n",
            "2024/12/03 15:27:45 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.09 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 3'].\n",
            "2024/12/03 15:27:45 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25, 42.09]\n",
            "2024/12/03 15:27:45 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:27:45 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:27:45 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:27:48 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of the QLS platform?', 'response': 'To provide a well-integrated ERP solution for schools'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  14%|█▍        | 1/7 [00:02<00:13,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:27:50 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What do badges in the admission inquiry list indicate?', 'response': 'The current status of the student'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  29%|██▊       | 2/7 [00:04<00:10,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:27:52 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where do you enter installment details?', 'response': 'In the Fees Master under Fees Installment'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  43%|████▎     | 3/7 [00:06<00:08,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:27:56 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where can you find MIS reports in the fees management module?', 'response': 'At multiple levels, from individual students to top management'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  57%|█████▋    | 4/7 [00:10<00:08,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:27:58 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of fee category titles?', 'response': 'To classify different types of fees'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  71%|███████▏  | 5/7 [00:12<00:05,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:00 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'How do you open a new registration form?', 'response': 'Click Registration > New Registration'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  86%|████████▌ | 6/7 [00:14<00:02,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:03 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What are the three steps in the admission process?', 'response': 'Inquiry, Registration, Admission'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%): 100%|██████████| 7/7 [00:17<00:00,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:03 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 7 (0.0%)\n",
            "2024/12/03 15:28:03 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 6', 'Predictor 0: Few-Shot Set 6'].\n",
            "2024/12/03 15:28:03 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25, 42.09, 0.0]\n",
            "2024/12/03 15:28:03 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:28:03 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:28:03 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:05 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of the QLS platform?', 'response': 'To provide a well-integrated ERP solution for schools'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  14%|█▍        | 1/7 [00:02<00:13,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:07 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What do badges in the admission inquiry list indicate?', 'response': 'The current status of the student'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  29%|██▊       | 2/7 [00:04<00:10,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:10 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where do you enter installment details?', 'response': 'In the Fees Master under Fees Installment'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  43%|████▎     | 3/7 [00:07<00:10,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:13 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where can you find MIS reports in the fees management module?', 'response': 'At multiple levels, from individual students to top management'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  57%|█████▋    | 4/7 [00:10<00:08,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:15 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of fee category titles?', 'response': 'To classify different types of fees'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  71%|███████▏  | 5/7 [00:12<00:05,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:17 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'How do you open a new registration form?', 'response': 'Click Registration > New Registration'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  86%|████████▌ | 6/7 [00:14<00:02,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:19 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What are the three steps in the admission process?', 'response': 'Inquiry, Registration, Admission'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%): 100%|██████████| 7/7 [00:16<00:00,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:19 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 7 (0.0%)\n",
            "2024/12/03 15:28:19 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 13', 'Predictor 0: Few-Shot Set 10'].\n",
            "2024/12/03 15:28:19 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25, 42.09, 0.0, 0.0]\n",
            "2024/12/03 15:28:19 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:28:19 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:28:19 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:22 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of the QLS platform?', 'response': 'To provide a well-integrated ERP solution for schools'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  14%|█▍        | 1/7 [00:02<00:13,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:25 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What do badges in the admission inquiry list indicate?', 'response': 'The current status of the student'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  29%|██▊       | 2/7 [00:05<00:14,  2.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:28 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where do you enter installment details?', 'response': 'In the Fees Master under Fees Installment'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  43%|████▎     | 3/7 [00:08<00:11,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:30 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where can you find MIS reports in the fees management module?', 'response': 'At multiple levels, from individual students to top management'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  57%|█████▋    | 4/7 [00:10<00:07,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:32 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of fee category titles?', 'response': 'To classify different types of fees'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  71%|███████▏  | 5/7 [00:12<00:04,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:34 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'How do you open a new registration form?', 'response': 'Click Registration > New Registration'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  86%|████████▌ | 6/7 [00:14<00:02,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:36 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What are the three steps in the admission process?', 'response': 'Inquiry, Registration, Admission'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%): 100%|██████████| 7/7 [00:16<00:00,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:36 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 7 (0.0%)\n",
            "2024/12/03 15:28:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 16'].\n",
            "2024/12/03 15:28:36 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25, 42.09, 0.0, 0.0, 0.0]\n",
            "2024/12/03 15:28:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:28:36 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:28:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:39 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of the QLS platform?', 'response': 'To provide a well-integrated ERP solution for schools'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  14%|█▍        | 1/7 [00:02<00:16,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:43 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What do badges in the admission inquiry list indicate?', 'response': 'The current status of the student'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  29%|██▊       | 2/7 [00:06<00:16,  3.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:45 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where do you enter installment details?', 'response': 'In the Fees Master under Fees Installment'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  43%|████▎     | 3/7 [00:08<00:10,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:47 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where can you find MIS reports in the fees management module?', 'response': 'At multiple levels, from individual students to top management'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  57%|█████▋    | 4/7 [00:10<00:07,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:49 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of fee category titles?', 'response': 'To classify different types of fees'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  71%|███████▏  | 5/7 [00:12<00:04,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:51 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'How do you open a new registration form?', 'response': 'Click Registration > New Registration'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  86%|████████▌ | 6/7 [00:14<00:02,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:53 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What are the three steps in the admission process?', 'response': 'Inquiry, Registration, Admission'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%): 100%|██████████| 7/7 [00:16<00:00,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:28:53 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 7 (0.0%)\n",
            "2024/12/03 15:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 0'].\n",
            "2024/12/03 15:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25, 42.09, 0.0, 0.0, 0.0, 0.0]\n",
            "2024/12/03 15:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 20 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 4.71 / 7 (67.2%): 100%|██████████| 7/7 [00:11<00:00,  1.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:05 INFO dspy.evaluate.evaluate: Average Metric: 4.707157114342743 / 7 (67.2%)\n",
            "2024/12/03 15:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 67.25 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 17'].\n",
            "2024/12/03 15:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25, 42.09, 0.0, 0.0, 0.0, 0.0, 67.25]\n",
            "2024/12/03 15:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 21 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 2.95 / 7 (42.1%): 100%|██████████| 7/7 [00:11<00:00,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:17 INFO dspy.evaluate.evaluate: Average Metric: 2.9464733536589827 / 7 (42.1%)\n",
            "2024/12/03 15:29:17 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.09 with parameters ['Predictor 0: Instruction 16', 'Predictor 0: Few-Shot Set 15'].\n",
            "2024/12/03 15:29:17 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25, 42.09, 0.0, 0.0, 0.0, 0.0, 67.25, 42.09]\n",
            "2024/12/03 15:29:17 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:29:17 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:29:17 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 22 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 2.95 / 7 (42.1%): 100%|██████████| 7/7 [00:12<00:00,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:29 INFO dspy.evaluate.evaluate: Average Metric: 2.9464733536589827 / 7 (42.1%)\n",
            "2024/12/03 15:29:29 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.09 with parameters ['Predictor 0: Instruction 17', 'Predictor 0: Few-Shot Set 3'].\n",
            "2024/12/03 15:29:29 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25, 42.09, 0.0, 0.0, 0.0, 0.0, 67.25, 42.09, 42.09]\n",
            "2024/12/03 15:29:29 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:29:29 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:29:29 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 23 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metric: 4.71 / 7 (67.2%): 100%|██████████| 7/7 [00:09<00:00,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:39 INFO dspy.evaluate.evaluate: Average Metric: 4.707157114342743 / 7 (67.2%)\n",
            "2024/12/03 15:29:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 67.25 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 3'].\n",
            "2024/12/03 15:29:39 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25, 42.09, 0.0, 0.0, 0.0, 0.0, 67.25, 42.09, 42.09, 67.25]\n",
            "2024/12/03 15:29:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:29:39 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:29:39 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 24 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:42 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of the QLS platform?', 'response': 'To provide a well-integrated ERP solution for schools'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  14%|█▍        | 1/7 [00:02<00:17,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:45 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What do badges in the admission inquiry list indicate?', 'response': 'The current status of the student'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  29%|██▊       | 2/7 [00:06<00:16,  3.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:47 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where do you enter installment details?', 'response': 'In the Fees Master under Fees Installment'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  43%|████▎     | 3/7 [00:08<00:10,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:49 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where can you find MIS reports in the fees management module?', 'response': 'At multiple levels, from individual students to top management'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  57%|█████▋    | 4/7 [00:10<00:07,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:51 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of fee category titles?', 'response': 'To classify different types of fees'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  71%|███████▏  | 5/7 [00:12<00:04,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:54 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'How do you open a new registration form?', 'response': 'Click Registration > New Registration'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  86%|████████▌ | 6/7 [00:14<00:02,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:56 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What are the three steps in the admission process?', 'response': 'Inquiry, Registration, Admission'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%): 100%|██████████| 7/7 [00:17<00:00,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:29:56 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 7 (0.0%)\n",
            "2024/12/03 15:29:56 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 18', 'Predictor 0: Few-Shot Set 9'].\n",
            "2024/12/03 15:29:56 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25, 42.09, 0.0, 0.0, 0.0, 0.0, 67.25, 42.09, 42.09, 67.25, 0.0]\n",
            "2024/12/03 15:29:56 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:29:56 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:29:56 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 25 / 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:00 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of the QLS platform?', 'response': 'To provide a well-integrated ERP solution for schools'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  14%|█▍        | 1/7 [00:03<00:22,  3.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:02 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What do badges in the admission inquiry list indicate?', 'response': 'The current status of the student'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  29%|██▊       | 2/7 [00:05<00:14,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:04 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where do you enter installment details?', 'response': 'In the Fees Master under Fees Installment'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  43%|████▎     | 3/7 [00:07<00:09,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:06 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'Where can you find MIS reports in the fees management module?', 'response': 'At multiple levels, from individual students to top management'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  57%|█████▋    | 4/7 [00:10<00:07,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:08 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is the purpose of fee category titles?', 'response': 'To classify different types of fees'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  71%|███████▏  | 5/7 [00:12<00:04,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:10 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'How do you open a new registration form?', 'response': 'Click Registration > New Registration'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%):  86%|████████▌ | 6/7 [00:14<00:02,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:14 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What are the three steps in the admission process?', 'response': 'Inquiry, Registration, Admission'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 7 (0.0%): 100%|██████████| 7/7 [00:17<00:00,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:14 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 7 (0.0%)\n",
            "2024/12/03 15:30:14 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n",
            "2024/12/03 15:30:14 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [58.96, 67.25, 42.09, 50.16, 56.76, 42.09, 14.29, 50.16, 42.09, 0.0, 0.0, 67.25, 67.25, 67.25, 67.25, 42.09, 0.0, 0.0, 0.0, 0.0, 67.25, 42.09, 42.09, 67.25, 0.0, 0.0]\n",
            "2024/12/03 15:30:14 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 67.25\n",
            "2024/12/03 15:30:14 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2024/12/03 15:30:14 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 67.25!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Optimize RAG\n",
        "tp = dspy.MIPROv2(metric=metric, auto=\"medium\", num_threads=1)\n",
        "\n",
        "optimized_rag = tp.compile(RAG(), trainset=trainset,\n",
        "                           max_bootstrapped_demos=2, max_labeled_demos=2,\n",
        "                           requires_permission_to_run=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(optimized_rag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "6mgTiZZcDzKG",
        "outputId": "3f5c1e7d-c4ef-49c6-a55a-2ac18d2cc135"
      },
      "id": "6mgTiZZcDzKG",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/18 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:16 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What is required to save a registration form?', 'response': 'Fill all required details and click Save'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 18 (0.0%):   6%|▌         | 1/18 [00:02<00:35,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:18 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'How do you generate an MIS report?', 'response': 'Select the required report level and click Generate'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 18 (0.0%):  11%|█         | 2/18 [00:03<00:31,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:20 ERROR dspy.utils.parallelizer: Error processing item Example({'question': \"Where is the 'New Registration' button located?\", 'response': 'Under the Registration menu'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 18 (0.0%):  17%|█▋        | 3/18 [00:06<00:30,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/03 15:30:22 ERROR dspy.utils.parallelizer: Error processing item Example({'question': 'What do fee structure details include?', 'response': 'Installment details, fee type, and categories'}) (input_keys={'question'}): litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}. Set `provide_traceback=True` to see the stack trace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 0.00 / 18 (0.0%):  22%|██▏       | 4/18 [00:07<00:27,  1.94s/it]"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/llms/anthropic/chat/handler.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model, messages, api_base, custom_prompt_dict, model_response, print_verbose, encoding, api_key, logging_obj, optional_params, timeout, acompletion, litellm_params, logger_fn, headers, client)\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                     response = client.post(\n\u001b[0m\u001b[1;32m    555\u001b[0m                         \u001b[0mapi_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/llms/custom_httpx/http_handler.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, params, headers, stream, timeout)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"message\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/llms/custom_httpx/http_handler.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, params, headers, stream, timeout)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '400 Bad Request' for url 'https://api.anthropic.com/v1/messages'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAnthropicError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m                 response = anthropic_chat_completions.completion(\n\u001b[0m\u001b[1;32m   1766\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/llms/anthropic/chat/handler.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model, messages, api_base, custom_prompt_dict, model_response, print_verbose, encoding, api_key, logging_obj, optional_params, timeout, acompletion, litellm_params, logger_fn, headers, client)\u001b[0m\n\u001b[1;32m    568\u001b[0m                         \u001b[0merror_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m                     raise AnthropicError(\n\u001b[0m\u001b[1;32m    570\u001b[0m                         \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnthropicError\u001b[0m: {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;31m# MODEL CALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   3008\u001b[0m         \u001b[0;31m## Map to OpenAI Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3009\u001b[0;31m         raise exception_type(\n\u001b[0m\u001b[1;32m   3010\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"litellm_response_headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitellm_response_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m                         \u001b[0mexception_mapping_worked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                         raise BadRequestError(\n\u001b[0m\u001b[1;32m    470\u001b[0m                             \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"AnthropicException - {error_str}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ceba169df963>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimized_rag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/evaluate/evaluate.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, program, metric, devset, num_threads, display_progress, display_table, return_all_scores, return_outputs)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/utils/parallelizer.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, function, data)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mwrapped_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_threads\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_isolated_single_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_multi_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/utils/parallelizer.py\u001b[0m in \u001b[0;36m_execute_isolated_single_thread\u001b[0;34m(self, function, data)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/utils/parallelizer.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcurrent_error_count\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovide_traceback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     logger.error(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/utils/parallelizer.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/evaluate/evaluate.py\u001b[0m in \u001b[0;36mprocess_item\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprocess_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/utils/callback.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# If no callbacks are provided, just call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# Generate call ID as the unique identifier for the call, this is useful for instrumentation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/primitives/program.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwith_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnamed_predictors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-fef4576d1dc1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, question)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print(\"Context Created\", context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrespond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSemanticF1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompositional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/utils/callback.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# If no callbacks are provided, just call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# Generate call ID as the unique identifier for the call, this is useful for instrumentation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/primitives/program.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwith_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnamed_predictors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/predict/chain_of_thought.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new_signature\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended_signature\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivated\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/utils/callback.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# If no callbacks are provided, just call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# Generate call ID as the unique identifier for the call, this is useful for instrumentation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/predict/predict.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwith_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/predict/predict.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mcompletions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2_5_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_parse_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             warn_once(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/predict/predict.py\u001b[0m in \u001b[0;36mv2_5_generate\u001b[0;34m(lm, lm_kwargs, signature, demos, inputs, _parse_values)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0madapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapter\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChatAdapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     return adapter(\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdemos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_parse_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/adapters/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, lm, lm_kwargs, signature, demos, inputs, _parse_values)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/utils/callback.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# If no callbacks are provided, just call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# Generate call ID as the unique identifier for the call, this is useful for instrumentation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/clients/lm.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, messages, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_litellm_text_completion\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlitellm_text_completion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         response = completion(\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mujson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/clients/lm.py\u001b[0m in \u001b[0;36mcached_litellm_completion\u001b[0;34m(request, num_retries)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcached_litellm_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     return litellm_completion(\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"no-cache\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"no-store\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/clients/lm.py\u001b[0m in \u001b[0;36mlitellm_completion\u001b[0;34m(request, num_retries, cache)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlitellm_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"no-cache\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"no-store\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mujson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     return litellm.completion(\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    991\u001b[0m                     ):\n\u001b[1;32m    992\u001b[0m                         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_retries\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion_with_retries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m                 elif (\n\u001b[1;32m    995\u001b[0m                     \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContextWindowExceededError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion_with_retries\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3040\u001b[0m             \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtenacity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_after_attempt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3041\u001b[0m         )\n\u001b[0;32m-> 3042\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mretryer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                     \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                 )  # DO NOT MAKE THREADED - router retry fallback relies on this!\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mprint_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error while checking max token limit: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;31m# MODEL CALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"stream\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   3007\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3008\u001b[0m         \u001b[0;31m## Map to OpenAI Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3009\u001b[0;31m         raise exception_type(\n\u001b[0m\u001b[1;32m   3010\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m             \u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception_mapping_worked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"litellm_response_headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitellm_response_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0merror_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLITELLM_EXCEPTION_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m                     ):\n\u001b[1;32m    468\u001b[0m                         \u001b[0mexception_mapping_worked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                         raise BadRequestError(\n\u001b[0m\u001b[1;32m    470\u001b[0m                             \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"AnthropicException - {error_str}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: litellm.BadRequestError: AnthropicException - {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.\"}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_rag.save(\"optimized_rag.json\")"
      ],
      "metadata": {
        "id": "VOWkk8QgD-wR"
      },
      "id": "VOWkk8QgD-wR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dspy.inspect_history(n=2)"
      ],
      "metadata": {
        "id": "_YgojrfSEN_e"
      },
      "id": "_YgojrfSEN_e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp optimized_rag.json /content/drive/MyDrive/Colab\\ Notebooks/GST-QA/"
      ],
      "metadata": {
        "id": "HEVzjqCUERIk"
      },
      "id": "HEVzjqCUERIk",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}